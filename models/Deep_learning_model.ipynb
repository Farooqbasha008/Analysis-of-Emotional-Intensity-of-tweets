{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBv4F2vY976qn0KCnuhMrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farooqbasha008/Analysis-of-Emotional-Intensity-of-tweets/blob/main/models/Deep_learning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL9MlwqFPmMS",
        "outputId": "21b86355-49f1-4753-cdf1-eda8aa75a834"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHUGLwTV49f",
        "outputId": "63c7e3f7-7a4c-4dc8-cce9-12c08e514b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 21s]\n",
            "mean_squared_error: 0.028210964053869247\n",
            "\n",
            "Best mean_squared_error So Far: 0.01227064710110426\n",
            "Total elapsed time: 00h 08m 34s\n",
            "Best Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 64\n",
            "learning_rate: 0.0001\n",
            "epochs: 150\n",
            "batch_size: 32\n",
            "units_1: 32\n",
            "units_2: 32\n",
            "units_3: 32\n",
            "units_4: 32\n",
            "99/99 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
            "Loss: [0.011582504026591778, 0.011582504026591778]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import BayesianOptimization\n",
        "import shutil\n",
        "\n",
        "# Read the train and test datasets\n",
        "train_df = pd.read_csv('trained.csv')\n",
        "test_df = pd.read_csv('tested.csv')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "train_df = train_df.drop('Unnamed: 0', axis=1)\n",
        "test_df = test_df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Prepare the train and test data\n",
        "X_train = train_df.iloc[:, :5]\n",
        "y_train = train_df['score']\n",
        "\n",
        "X_test = test_df.iloc[:, :5]\n",
        "y_test = test_df['score']\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the build_model function\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Tune the number of layers\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=5)\n",
        "    for i in range(num_layers):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=32),\n",
        "                        activation='relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer=Adam(\n",
        "                    learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=[MeanSquaredError()])\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=hp.Int('epochs', min_value=50, max_value=200, step=50),\n",
        "                        batch_size=hp.Int('batch_size', min_value=32, max_value=128, step=32),\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        verbose=0)\n",
        "\n",
        "    return model\n",
        "\n",
        "checkpoint_dir = 'my_dir/emotional_intensity'\n",
        "\n",
        "# Clear the checkpoint directory if it exists\n",
        "shutil.rmtree(checkpoint_dir, ignore_errors=True)\n",
        "\n",
        "# Initialize the Keras Tuner BayesianOptimization tuner\n",
        "tuner = BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='mean_squared_error',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory='my_dir',\n",
        "    project_name='emotional_intensity',\n",
        "    overwrite = True\n",
        ")\n",
        "\n",
        "# Perform the hyperparameter search\n",
        "tuner.search(X_train, y_train)\n",
        "\n",
        "# Retrieve the best model and evaluate it\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "for hyperparameter, value in best_hyperparameters.values.items():\n",
        "    print(f\"{hyperparameter}: {value}\")\n",
        "\n",
        "loss = best_model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the obtained hyperparameters\n",
        "model = Sequential()\n",
        "\n",
        "# Add the layers based on the best hyperparameters\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=[MeanSquaredError()])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "# Calculate y_pred\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Flatten y_pred if necessary\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (R2):\", r2)\n",
        "\n",
        "# Calculate RMSLE\n",
        "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
        "print(\"Root Mean Squared Logarithmic Error (RMSLE):\", rmsle)\n",
        "\n",
        "# Calculate MAPE\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmLyjaYrP7RG",
        "outputId": "d91a95be-61c7-4826-e043-17309b763197"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "79/79 [==============================] - 2s 6ms/step - loss: 0.2780 - mean_squared_error: 0.2780 - val_loss: 0.2254 - val_mean_squared_error: 0.2254\n",
            "Epoch 2/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.1701 - mean_squared_error: 0.1701 - val_loss: 0.1093 - val_mean_squared_error: 0.1093\n",
            "Epoch 3/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0645 - mean_squared_error: 0.0645 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
            "Epoch 4/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
            "Epoch 5/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 6/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
            "Epoch 7/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
            "Epoch 8/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
            "Epoch 9/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 10/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 11/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 12/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
            "Epoch 13/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
            "Epoch 14/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 15/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 16/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
            "Epoch 17/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
            "Epoch 18/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
            "Epoch 19/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
            "Epoch 20/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
            "Epoch 21/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
            "Epoch 22/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
            "Epoch 23/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
            "Epoch 24/150\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
            "Epoch 25/150\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
            "Epoch 26/150\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
            "Epoch 27/150\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
            "Epoch 28/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
            "Epoch 29/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
            "Epoch 30/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
            "Epoch 31/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
            "Epoch 32/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
            "Epoch 33/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0336 - val_mean_squared_error: 0.0336\n",
            "Epoch 34/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
            "Epoch 35/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
            "Epoch 36/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
            "Epoch 37/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0321 - val_mean_squared_error: 0.0321\n",
            "Epoch 38/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0315 - val_mean_squared_error: 0.0315\n",
            "Epoch 39/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
            "Epoch 40/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
            "Epoch 41/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
            "Epoch 42/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0293 - val_mean_squared_error: 0.0293\n",
            "Epoch 43/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
            "Epoch 44/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
            "Epoch 45/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
            "Epoch 46/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
            "Epoch 47/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
            "Epoch 48/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
            "Epoch 49/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
            "Epoch 50/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
            "Epoch 51/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
            "Epoch 52/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
            "Epoch 53/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
            "Epoch 54/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 55/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 56/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 57/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 58/150\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 59/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 60/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 61/150\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 62/150\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 63/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 64/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "Epoch 65/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 66/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 67/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 68/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 69/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 70/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 71/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 72/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 73/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 74/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 75/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 76/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 77/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 78/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 79/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 80/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 81/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 82/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 83/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 84/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 85/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 86/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 87/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 88/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 89/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 90/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 91/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 92/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 93/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 94/150\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 95/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 96/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 97/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 98/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 99/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 100/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 101/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 102/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 103/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 104/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 105/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 106/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 107/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 108/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 109/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 110/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 111/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 112/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 113/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 114/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 115/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 116/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 117/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 118/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 119/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 120/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 121/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 122/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 123/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 124/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 125/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 126/150\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 127/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 128/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 129/150\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 130/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 131/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 132/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 133/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 134/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 135/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 136/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 137/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 138/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 139/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 140/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 141/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 142/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 143/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 144/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 145/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 146/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 147/150\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 148/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 149/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 150/150\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "99/99 [==============================] - 0s 1ms/step\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
            "Loss: [0.011815403588116169, 0.011815403588116169]\n",
            "Mean Absolute Error (MAE): 0.06174608447512269\n",
            "Mean Squared Error (MSE): 0.011815403851371722\n",
            "Root Mean Squared Error (RMSE): 0.10869868376099005\n",
            "R-squared (R2): 0.700356813488701\n",
            "Root Mean Squared Logarithmic Error (RMSLE): 0.07315033491579366\n",
            "Mean Absolute Percentage Error (MAPE): inf\n"
          ]
        }
      ]
    }
  ]
}